{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mamba create -n rvc mamba python=3.9.16 jupyter -y > /dev/null\n!source /opt/conda/bin/activate rvc > /dev/null\n!sudo rm -f /opt/conda/bin/python /opt/conda/bin/python3 /opt/conda/bin/python3.9\n!sudo ln -sf /opt/conda/envs/rvc/bin/python3 /opt/conda/bin/python\n!sudo ln -sf /opt/conda/envs/rvc/bin/python3 /opt/conda/bin/python3\n!sudo ln -sf /opt/conda/envs/rvc/bin/python3.9 /opt/conda/bin/python3.9","metadata":{"_uuid":"6bad080f-279e-4837-bb72-5263180f019d","_cell_guid":"7329bdbb-f3e9-461b-9aa5-8b013109e8d3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-30T06:00:08.314561Z","iopub.execute_input":"2023-07-30T06:00:08.314985Z","iopub.status.idle":"2023-07-30T06:04:41.936412Z","shell.execute_reply.started":"2023-07-30T06:00:08.314949Z","shell.execute_reply":"2023-07-30T06:04:41.934956Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c6f2354e.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/86b0f08d.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/c9ddbd6b.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/b121c3e7.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/497deca9.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/09cdf8bf.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/47929eba.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/3e39a7aa.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/2ce54b42.json\" was modified by another program\n\u001b[33m\u001b[1mwarning  libmamba\u001b[m Cache file \"/opt/conda/pkgs/cache/4ea078d6.json\" was modified by another program\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone --quiet https://github.com/cepLI/rvc\n%cd /kaggle/working/rvc/\n!python -m pip install -r requirements.txt --no-warn-script-location --quiet","metadata":{"_uuid":"ba1de19f-d6d8-4c55-8535-a8383478f7d8","_cell_guid":"b6399414-7886-4fde-a9c2-a45d16899938","execution":{"iopub.status.busy":"2023-07-30T06:13:39.781171Z","iopub.execute_input":"2023-07-30T06:13:39.781612Z","iopub.status.idle":"2023-07-30T06:18:03.536044Z","shell.execute_reply.started":"2023-07-30T06:13:39.781576Z","shell.execute_reply":"2023-07-30T06:18:03.534654Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"/kaggle/working\n/kaggle/working/rvc\n\u001b[33mDEPRECATION: omegaconf 2.0.5 has a non-standard dependency specifier PyYAML>=5.1.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!apt install aria2 -y &> /dev/null\n!aria2c --quiet https://bit.ly/f0G40k_pth -d pretrained_v2 -o f0G40k.pth\n!aria2c --quiet https://bit.ly/f0D40k_pth -d pretrained_v2 -o f0D40k.pth\n!aria2c --quiet https://bit.ly/hubert_base_pt -o hubert_base.pt","metadata":{"_uuid":"5534a86d-d03d-4002-bd39-cdfc7c64c5e2","_cell_guid":"a5ced257-24fb-4cec-af84-be0a323b26bb","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-30T06:24:41.603210Z","iopub.execute_input":"2023-07-30T06:24:41.603672Z","iopub.status.idle":"2023-07-30T06:24:51.043370Z","shell.execute_reply.started":"2023-07-30T06:24:41.603636Z","shell.execute_reply":"2023-07-30T06:24:51.041863Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!mkdir -p /kaggle/temp/dataset\n!cp -r /kaggle/input/* /kaggle/temp/dataset/\n!mv /kaggle/temp/dataset/*/* /kaggle/temp/dataset/\n!rm -r /kaggle/temp/dataset/*/","metadata":{"_uuid":"fcc82082-f6ed-4ac5-a4d6-8d3a03765b2f","_cell_guid":"193c99c4-105e-44de-838d-10adc645c5d7","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-07-30T06:27:49.555560Z","iopub.execute_input":"2023-07-30T06:27:49.556004Z","iopub.status.idle":"2023-07-30T06:27:53.847794Z","shell.execute_reply.started":"2023-07-30T06:27:49.555967Z","shell.execute_reply":"2023-07-30T06:27:53.846126Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/rvc/\n!python infer-web.py --pycmd python --kaggle","metadata":{"_uuid":"fc51dc29-2686-4e52-b59b-8ca4cc56672a","_cell_guid":"f50974ad-c505-43fd-b822-aa37d51bd106","collapsed":true,"jupyter":{"outputs_hidden":true},"execution":{"iopub.status.busy":"2023-07-30T06:28:09.916573Z","iopub.execute_input":"2023-07-30T06:28:09.917020Z","iopub.status.idle":"2023-07-30T06:35:13.334506Z","shell.execute_reply.started":"2023-07-30T06:28:09.916984Z","shell.execute_reply":"2023-07-30T06:35:13.333156Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"/kaggle/working/rvc\nFound GPU Tesla T4\nUse Language: en_US\nRunning on local URL:  http://127.0.0.1:7860\nRunning on public URL: https://6d6722a6d35d1ddffe.gradio.live\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\npython trainset_preprocess_pipeline_print.py \"/kaggle/temp/dataset\" 40000 2 \"/kaggle/working/rvc/logs/kontsevich-test\" False\n['trainset_preprocess_pipeline_print.py', '/kaggle/temp/dataset', '40000', '2', '/kaggle/working/rvc/logs/kontsevich-test', 'False']\nstart preprocess\n['trainset_preprocess_pipeline_print.py', '/kaggle/temp/dataset', '40000', '2', '/kaggle/working/rvc/logs/kontsevich-test', 'False']\n/kaggle/temp/dataset/kontsevich-test.mp3->Suc.\nend preprocess\nstart preprocess\n['trainset_preprocess_pipeline_print.py', '/kaggle/temp/dataset', '40000', '2', '/kaggle/working/rvc/logs/kontsevich-test', 'False']\n/kaggle/temp/dataset/kontsevich-test.mp3->Suc.\nend preprocess\n\npython extract_f0_print.py \"/kaggle/working/rvc/logs/kontsevich-test\" 2 harvest\n['extract_f0_print.py', '/kaggle/working/rvc/logs/kontsevich-test', '2', 'harvest']\ntodo-f0-16\nf0ing,now-0,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_1.wav\ntodo-f0-16\nf0ing,now-0,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_10.wav\nf0ing,now-3,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_19.wav\nf0ing,now-3,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_2.wav\nf0ing,now-6,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_28.wav\nf0ing,now-6,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_26.wav\nf0ing,now-9,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_35.wav\nf0ing,now-9,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_34.wav\nf0ing,now-12,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_42.wav\nf0ing,now-12,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_41.wav\nf0ing,now-15,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_8.wav\nf0ing,now-15,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_7.wav\n['extract_f0_print.py', '/kaggle/working/rvc/logs/kontsevich-test', '2', 'harvest']\ntodo-f0-16\nf0ing,now-0,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_1.wav\ntodo-f0-16\nf0ing,now-0,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_10.wav\nf0ing,now-3,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_19.wav\nf0ing,now-3,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_2.wav\nf0ing,now-6,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_28.wav\nf0ing,now-6,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_26.wav\nf0ing,now-9,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_35.wav\nf0ing,now-9,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_34.wav\nf0ing,now-12,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_42.wav\nf0ing,now-12,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_41.wav\nf0ing,now-15,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_8.wav\nf0ing,now-15,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_7.wav\n\npython extract_feature_print.py cuda:0 1 0 0 \"/kaggle/working/rvc/logs/kontsevich-test\" v2\n['extract_feature_print.py', 'cuda:0', '1', '0', '0', '/kaggle/working/rvc/logs/kontsevich-test', 'v2']\n/kaggle/working/rvc/logs/kontsevich-test\nload model(s) from hubert_base.pt\n2023-07-30 06:30:15 | INFO | fairseq.tasks.hubert_pretraining | current directory is /kaggle/working/rvc\n2023-07-30 06:30:15 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'metadata', 'fine_tuning': False, 'labels': ['km'], 'label_dir': 'label', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\n2023-07-30 06:30:15 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\nmove model to cuda\nall-feature-32\nnow-32,all-0,0_1.wav,(102, 768)\nnow-32,all-3,0_13.wav,(149, 768)\nnow-32,all-6,0_19.wav,(125, 768)\nnow-32,all-9,0_22.wav,(101, 768)\nnow-32,all-12,0_26.wav,(149, 768)\nnow-32,all-15,0_30.wav,(89, 768)\nnow-32,all-18,0_34.wav,(149, 768)\nnow-32,all-21,0_38.wav,(145, 768)\nnow-32,all-24,0_41.wav,(160, 768)\nnow-32,all-27,0_45.wav,(159, 768)\nnow-32,all-30,0_7.wav,(149, 768)\nall-feature-done\n['extract_f0_print.py', '/kaggle/working/rvc/logs/kontsevich-test', '2', 'harvest']\ntodo-f0-16\nf0ing,now-0,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_1.wav\ntodo-f0-16\nf0ing,now-0,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_10.wav\nf0ing,now-3,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_19.wav\nf0ing,now-3,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_2.wav\nf0ing,now-6,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_28.wav\nf0ing,now-6,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_26.wav\nf0ing,now-9,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_35.wav\nf0ing,now-9,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_34.wav\nf0ing,now-12,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_42.wav\nf0ing,now-12,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_41.wav\nf0ing,now-15,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_8.wav\nf0ing,now-15,all-16,-/kaggle/working/rvc/logs/kontsevich-test/1_16k_wavs/0_7.wav\n['extract_feature_print.py', 'cuda:0', '1', '0', '0', '/kaggle/working/rvc/logs/kontsevich-test', 'v2']\n/kaggle/working/rvc/logs/kontsevich-test\nload model(s) from hubert_base.pt\nmove model to cuda\nall-feature-32\nnow-32,all-0,0_1.wav,(102, 768)\nnow-32,all-3,0_13.wav,(149, 768)\nnow-32,all-6,0_19.wav,(125, 768)\nnow-32,all-9,0_22.wav,(101, 768)\nnow-32,all-12,0_26.wav,(149, 768)\nnow-32,all-15,0_30.wav,(89, 768)\nnow-32,all-18,0_34.wav,(149, 768)\nnow-32,all-21,0_38.wav,(145, 768)\nnow-32,all-24,0_41.wav,(160, 768)\nnow-32,all-27,0_45.wav,(159, 768)\nnow-32,all-30,0_7.wav,(149, 768)\nall-feature-done\n\nwrite filelist done\nuse gpus: 0\npython train_nsf_sim_cache_sid_load_pretrain.py -e \"kontsevich-test\" -sr 40k -f0 1 -bs 20 -g 0 -te 10 -se 10 -pg pretrained_v2/f0G40k.pth -pd pretrained_v2/f0D40k.pth -l 1 -c 0 -sw 0 -v v2\nINFO:kontsevich-test:{'train': {'log_interval': 200, 'seed': 1234, 'epochs': 20000, 'learning_rate': 0.0001, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 20, 'fp16_run': True, 'lr_decay': 0.999875, 'segment_size': 12800, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'max_wav_value': 32768.0, 'sampling_rate': 40000, 'filter_length': 2048, 'hop_length': 400, 'win_length': 2048, 'n_mel_channels': 125, 'mel_fmin': 0.0, 'mel_fmax': None, 'training_files': './logs/kontsevich-test/filelist.txt'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [10, 10, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'use_spectral_norm': False, 'gin_channels': 256, 'spk_embed_dim': 109}, 'model_dir': './logs/kontsevich-test', 'experiment_dir': './logs/kontsevich-test', 'save_every_epoch': 10, 'name': 'kontsevich-test', 'total_epoch': 10, 'pretrainG': 'pretrained_v2/f0G40k.pth', 'pretrainD': 'pretrained_v2/f0D40k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '40k', 'if_f0': 1, 'if_latest': 1, 'save_every_weights': '0', 'if_cache_data_in_gpu': 0}\nINFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\nINFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\ngin_channels: 256 self.spk_embed_dim: 109\nINFO:kontsevich-test:loaded pretrained pretrained_v2/f0G40k.pth\n<All keys matched successfully>\nINFO:kontsevich-test:loaded pretrained pretrained_v2/f0D40k.pth\n<All keys matched successfully>\n/opt/conda/envs/rvc/lib/python3.9/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\nNote: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n/opt/conda/envs/rvc/lib/python3.9/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\nNote: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\n/opt/conda/envs/rvc/lib/python3.9/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\nNote: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at ../aten/src/ATen/native/SpectralOps.cpp:862.)\n  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\nINFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\n/opt/conda/envs/rvc/lib/python3.9/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\ngrad.sizes() = [64, 1, 4], strides() = [4, 1, 1]\nbucket_view.sizes() = [64, 1, 4], strides() = [4, 4, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:323.)\n  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\nINFO:kontsevich-test:Train Epoch: 1 [0%]\nINFO:kontsevich-test:[0, 0.0001]\nINFO:kontsevich-test:loss_disc=4.093, loss_gen=3.117, loss_fm=13.939,loss_mel=29.036, loss_kl=6.668\nDEBUG:matplotlib:matplotlib data path: /opt/conda/envs/rvc/lib/python3.9/site-packages/matplotlib/mpl-data\nDEBUG:matplotlib:CONFIGDIR=/root/.config/matplotlib\nDEBUG:matplotlib:interactive is False\nDEBUG:matplotlib:platform is linux\nINFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\nINFO:kontsevich-test:====> Epoch: 1 [2023-07-30 06:33:37] | (0:00:20.014282)\n/opt/conda/envs/rvc/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\nINFO:kontsevich-test:====> Epoch: 2 [2023-07-30 06:33:43] | (0:00:06.256717)\nINFO:kontsevich-test:====> Epoch: 3 [2023-07-30 06:33:49] | (0:00:06.095577)\nINFO:kontsevich-test:====> Epoch: 4 [2023-07-30 06:33:56] | (0:00:06.148125)\nINFO:kontsevich-test:====> Epoch: 5 [2023-07-30 06:34:02] | (0:00:06.183902)\nINFO:kontsevich-test:====> Epoch: 6 [2023-07-30 06:34:08] | (0:00:06.145557)\nINFO:kontsevich-test:====> Epoch: 7 [2023-07-30 06:34:14] | (0:00:06.163955)\nINFO:kontsevich-test:====> Epoch: 8 [2023-07-30 06:34:20] | (0:00:06.212722)\nINFO:kontsevich-test:====> Epoch: 9 [2023-07-30 06:34:27] | (0:00:06.339315)\nINFO:kontsevich-test:Saving model and optimizer state at epoch 10 to ./logs/kontsevich-test/G_2333333.pth\nINFO:kontsevich-test:Saving model and optimizer state at epoch 10 to ./logs/kontsevich-test/D_2333333.pth\nINFO:kontsevich-test:====> Epoch: 10 [2023-07-30 06:34:36] | (0:00:09.088492)\nINFO:kontsevich-test:Training is done. The program is closed.\nINFO:kontsevich-test:saving final ckpt:Success.\n/opt/conda/envs/rvc/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 14 leaked semaphore objects to clean up at shutdown\n  warnings.warn('resource_tracker: There appear to be %d '\n^C\nKeyboard interruption in main thread... closing server.\nKilling tunnel 127.0.0.1:7860 <> https://6d6722a6d35d1ddffe.gradio.live\n","output_type":"stream"}]},{"cell_type":"code","source":"%cd /kaggle/working/rvc/\n!zip -r out.zip weights logs\n%cd /kaggle/working/\nfrom IPython.display import FileLink\nFileLink(r'out.zip')","metadata":{"execution":{"iopub.status.busy":"2023-07-30T06:43:23.730859Z","iopub.execute_input":"2023-07-30T06:43:23.731557Z","iopub.status.idle":"2023-07-30T06:43:23.742363Z","shell.execute_reply.started":"2023-07-30T06:43:23.731516Z","shell.execute_reply":"2023-07-30T06:43:23.741161Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/out.zip","text/html":"<a href='out.zip' target='_blank'>out.zip</a><br>"},"metadata":{}}]}]}